import os, sys, json
import numpy as np
from Model import Model

class MainPipeliner:
    """
        Runs all the models in the dataset and reports accuracy on
        each one of them. The user can configure which stats to
        show for the accuracy. The default shown is the log loss
        as it is the default on the MMCC.
    """

    def __init__(self, input_file=None, summary_file=None):
        """
            Loads the config parameters from a file. This parameters
            include the input and output files, the models and
            probably [TODO: more input parameters]
        """

        self._config_file = 'config.json'
        self._file_contents = json.load(self._config_file)

        if input_file == None:
            input_file = self._file_contents['input_file'].strip()

        if summary_file == None:
            summary_file = self._file_contents['summary_file'].strip()

        self.input_file = input_file
        self.summary_file = summary_file
        self.models = []
        self._temp_output_files = []

        if self.input_file == '' or self.summary_file == '':
            raise Exception('No input or output file specified')

    def load_models(self):
        """
            Loads all the models from their respective files included
            on the json file. The specification of how to use this will
            be in TODO:HERE.
        """
        for m in self._file_contents['models']:
            arguments = []

            for arg in m['arguments']:
                arguments.extend(arg)

            self.models.append(Model(m['name'], arguments,
                                    m['script_name']))


    def run_sequential(self):
        """
            Runs all the modules in one processor. The output
            is reported on the file specified on the configuration
            file.
        """
        from datetime import datetime

        summary = file(self.summary_file, "w")

        for m in self.modules:
            d = datetime.fromtimestamp(time.time()
                        ).strftime("%Y-%m-%d %H:%M:%S")
            self._temp_output_files.append(m.name + "_" + d)
            m.run_model(self.input_file, self._temp_output_files[-1])

            ll = self._process_output(m, self._temp_output_files[-1])
            summary.write(ll + "\n") #Â Check this ....
            print ll


    def _process_output(self, results_file, verbose=False):
        """
            Processes the output generated by one of the clasification
            algorithms.

            Arguments:
            `results_file`: File in which the results of running a model
                           will be stored.
            `verbose` : Whether some more information is wanted, for now
                        this is just the confusion matrix. More things on
                        the future.
        """
        results = np.loadtxt(results_file, skiprows=1, delimiter=',',
                            dtype="S")
        log_loss = self._log_loss(np.array(results[:, 1:]))

        if verbose:
            # Print the confusion matrix
            pass
        return log_loss

    def _log_loss(self, data):
        """
            Calculate the log loss for certain result of the run of
            the model.
        """

        ll = 0
        for i in xrange(data.shape[0]):
            for j in xrange(data.shape[1]):
                ll += np.log(data[i,j])

        ll *= -1/data.shape[0]

        return ll

def main():
    mp = MainPipeliner()
    mp.load_models()
    mp.run_sequential()

if __name__ == '__main__':
    main()
